{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions/ Read me\n",
    "1. Program starts by fetching data from given cnn url, two main dictionary is declared, one for stock with symbol as key(key-value pair) and one for stock details for the symbol (Price,open,volume).\n",
    "2. First function fetches all the symbols from the a href tags and fills the main dictionary with symbol and name\n",
    "3. Second function scraps all the data required from symbol and name stored in the main dictionary\n",
    "4. Third function writes to csv file using the second dictionary (Excel file must not be open, in order for file to be generated)\n",
    "5. Finally stock details are displayed and user is given a choice to enter a stock of their choice to see further details.\n",
    "6. If given stock does not exist, exception is handled.\n",
    "7. Between starting the program and the file being written, there's a small amount of wait period after which the user input in prompted since data has to be fetched, stored and written to file.\n",
    "\n",
    "Reference used:\n",
    "https://regex101.com/\n",
    "https://towardsdatascience.com/web-scraping-with-python-beautifulsoup-40d2ce4b6252\n",
    "https://www.datacamp.com/community/tutorials/amazon-web-scraping-using-beautifulsoup\n",
    "https://stackabuse.com/reading-and-writing-csv-files-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "This is a program to scrape data from the https://money.cnn.com/data/hotstocks/  for a class project. \n",
      "Which stock are you interested in: \n",
      "\n",
      "\n",
      "Most Active\n",
      "\n",
      "\n",
      "GE :  General Electric Co\n",
      "PFE :  Pfizer Inc\n",
      "T :  AT&amp;T Inc\n",
      "F :  Ford Motor Co\n",
      "CCL :  Carnival Corp\n",
      "MRO :  Marathon Oil Corp\n",
      "BAC :  Bank of America Corp\n",
      "OXY :  Occidental Petroleum Corp\n",
      "XOM :  Exxon Mobil Corp\n",
      "WFC :  Wells Fargo &amp; Co\n",
      "\n",
      "\n",
      "Gainers\n",
      "\n",
      "\n",
      "EFX :  Equifax Inc\n",
      "NCLH :  Norwegian Cruise Line Holdings Ltd\n",
      "MRO :  Marathon Oil Corp\n",
      "OXY :  Occidental Petroleum Corp\n",
      "LUMN :  Centurylink Inc\n",
      "HAL :  Halliburton Co\n",
      "T :  AT&amp;T Inc\n",
      "PXD :  Pioneer Natural Resources Co\n",
      "XOM :  Exxon Mobil Corp\n",
      "MTD :  Mettler-Toledo International Inc\n",
      "\n",
      "\n",
      "Losers\n",
      "\n",
      "\n",
      "LEN :  Lennar Corp\n",
      "DHI :  D.R. Horton Inc\n",
      "LEG :  Leggett &amp; Platt Inc\n",
      "PHM :  Pultegroup Inc\n",
      "NI :  NiSource Inc\n",
      "WHR :  Whirlpool Corp\n",
      "FLT :  Fleetcor Technologies Inc\n",
      "AVB :  Avalonbay Communities Inc\n",
      "KIM :  Kimco Realty Corp\n",
      "D :  Dominion Energy Inc\n",
      "\n",
      "\n",
      "stocks.csv file successfully written\n",
      "\n",
      "\n",
      "Categories\n",
      "Most Active\n",
      "Gainers\n",
      "Losers\n",
      "User inputs: w\n",
      "No such stock found, please try again\n",
      "User inputs:  \n",
      "No such stock found, please try again\n",
      "User inputs: a\n",
      "No such stock found, please try again\n",
      "User inputs: 2\n",
      "No such stock found, please try again\n",
      "User inputs:  \n",
      "No such stock found, please try again\n",
      "User inputs: KIM\n",
      "\n",
      "\n",
      "The data for  KIM  is the following: \n",
      "\n",
      "\n",
      "KIM Kimco Realty Corp\n",
      "OPEN:  14.77\n",
      "PREV CLOSE:   14.94\n",
      "VOLUME: 3,280,770\n",
      "MARKET CAP: $6.8B\n",
      "\n",
      "\n",
      "Program successfully completed\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error \n",
    "from bs4 import BeautifulSoup \n",
    "import ssl\n",
    "import re\n",
    "import csv\n",
    "\n",
    "#Generating csv file with data from filevalue dictionary\n",
    "def writeFile(category):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    #Existing file should not be opened, else file won't be written (filename - stocks.csv)\n",
    "    with open('stocks.csv', 'w',newline='') as csvfile:\n",
    "        #key list \n",
    "        excelColumns = ['Category', 'StockSymbol','Name','Opening','Previousclose','Volume','Market']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=excelColumns)\n",
    "        writer.writeheader()\n",
    "        #Writing to file based on all our key values from stock details dictionary (fileValue)\n",
    "        for link in fileValue:\n",
    "            tempDict = stockDict[link]\n",
    "            #Key - Column names, values - stock details \n",
    "            writer.writerow({'Category':stockCategory[j],'StockSymbol':tempDict['Link'],'Name':tempDict['Name'],'Opening':tempDict['Open'],'Previousclose':tempDict['PrevClose'],'Volume':tempDict['Volume'],'Market':tempDict['MarketCap']})\n",
    "            i = i + 1\n",
    "            if(i%10==0):\n",
    "                j = j + 1         \n",
    "    \n",
    "#fetch stockdetails based on key values from stock Dictionary    \n",
    "def appendData(url,pattern):\n",
    "    #running the loop to fetch all details based on each key\n",
    "    for key in stockDict.keys():\n",
    "        uniqueKey = key\n",
    "        tempDict = stockDict[uniqueKey]\n",
    "        #key list for the main dictionary\n",
    "        keyList = ['PrevClose','Open','Range','Volume','AvgVolume','MarketCap']\n",
    "        url = \"https://money.cnn.com/quote/quote.html?symb=\" + uniqueKey\n",
    "        html = urllib.request.urlopen(url)\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        #find all the table data using table class\n",
    "        rows = soup.find_all('table',{'class':\"wsod_dataTable wsod_dataTableBig\"})\n",
    "        rowSet = rows[0].find_all('tr')\n",
    "        #print(type(rowSet))\n",
    "        #print(\"saraarar\")\n",
    "        i = 0\n",
    "        #fetching all data using \"td\" and using regex to get the exact data needeed\n",
    "        for row in rowSet:\n",
    "            dataSet = row.find_all('td')\n",
    "            dataSets = str(dataSet[1])\n",
    "            tableValues = pattern\n",
    "            tableValue = (re.sub(tableValues, '',dataSets))\n",
    "            tempDict[keyList[i]] = tableValue\n",
    "            i = i + 1\n",
    "        stockDict[uniqueKey] = tempDict\n",
    "\n",
    "def fetchFillData(data):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for row in rows:\n",
    "        #temporary dictionary to assign key with all details as value, key - stock, value - details\n",
    "        dictTemp = dict()\n",
    "        \n",
    "        #find all the a href tags to get keys\n",
    "        linkSet = row.find_all('a')\n",
    "        #print(\"printing links\",linkSet)\n",
    "        #print(type(linkSet))\n",
    "        links = str(linkSet)\n",
    "        #print(\"printing string of links\",links)\n",
    "        #Using regex to get only the value we need\n",
    "        regexPattern = re.compile('<.*?>')\n",
    "        #print(\"printing clean links\",regexPattern)\n",
    "        stockValue = (re.sub(regexPattern, '',links))\n",
    "        #print(\"printing clean links 2\",stockValue)\n",
    "        \n",
    "        #Now to fetch all the value(details) for the same stock\n",
    "        spanSet = row.find_all('span')\n",
    "        #print(\"printing span\",spanSet)\n",
    "        spans = str(spanSet)\n",
    "       # print(\"printing string of span\",spans)\n",
    "        #Using regex to get only the value we need\n",
    "        spanValue = (re.sub(regexPattern, '',spans))\n",
    "        #print(\"printing clean links 2 again?\",spanValue)\n",
    "        spanLength = len(spanValue)\n",
    "        #Appending to dictionary (key,value - stock, details) and stock details \n",
    "        if(spanLength <= 2): continue\n",
    "        spanList = spanValue.split(',')\n",
    "        dictTemp['Link'] = stockValue[1:-1]\n",
    "        dictTemp['Name'] = spanList[0][1:]\n",
    "        stockDict[dictTemp['Link']] = dictTemp\n",
    "        #print(dictTemp['Link'],\" \",dictTemp['Name'])\n",
    "        if( i%10==0 ):\n",
    "            print(\"\\n\")\n",
    "            print(stockCategory[j])\n",
    "            print(\"\\n\")\n",
    "            j = j + 1\n",
    "        print(dictTemp['Link'],\": \",dictTemp['Name'])\n",
    "        fileValue.append(dictTemp['Link'])\n",
    "        i = i + 1\n",
    "        #print(\"sarascvs\",fileValue)\n",
    "        \n",
    "\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = \"https://money.cnn.com/data/hotstocks/\"\n",
    "html = urllib.request.urlopen(url, context=ctx).read() \n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "\n",
    "#Get all tr rows from parsed HTML\n",
    "rows = soup.find_all('tr')\n",
    "#rows = set\n",
    "#print(type(rows))\n",
    "#Count of all tr rows found\n",
    "rowsLength = len(rows)\n",
    "#rowslength = 33\n",
    "#print(\"rowsLength\",rowsLength)\n",
    "\n",
    "regexPattern = re.compile('<.*?>')\n",
    "stockCategory = ['Most Active','Gainers','Losers']\n",
    "stockDict = dict()\n",
    "fileValue = list()\n",
    "print(\"\\n\")\n",
    "print(\"This is a program to scrape data from the https://money.cnn.com/data/hotstocks/  for a class project. \")\n",
    "print(\"Which stock are you interested in: \")\n",
    "\n",
    "\n",
    "\n",
    "#Write to two main dictinary, one to write to file, one to store key value pair of stock-details\n",
    "fetchFillData(rows)\n",
    "#print(\"saraFictr:\",stockDict)\n",
    "#print(\"saraFile:\",fileValue)\n",
    "\n",
    "#Now to get all data based on the key from stock dictionary\n",
    "appendData(html,regexPattern)\n",
    "#print(\"saraFictr:\",stockDict)\n",
    "\n",
    "#write to csv filewith keys as stock symbols stored in fileValue dictionary (31 records should be written to file)\n",
    "writeFile(stockCategory)\n",
    "print(\"\\n\")\n",
    "print(\"stocks.csv file successfully written\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Categories\")\n",
    "print(stockCategory[0])\n",
    "print(stockCategory[1])\n",
    "print(stockCategory[2])\n",
    "\n",
    "loopFlag = True\n",
    "#print(\"sardicttionary\",stockDict)\n",
    "while loopFlag:\n",
    "        userChoice = input(\"User inputs: \")\n",
    "        if userChoice in stockDict:\n",
    "            #print(\"key exists\")\n",
    "            loopFlag = False\n",
    "            stockDetail = stockDict.get(userChoice)\n",
    "            print(\"\\n\")\n",
    "            #['PrevClose','Open','Range','Volume','AvgVolume','MarketCap']\n",
    "            print(\"The data for \",userChoice,\" is the following: \")\n",
    "            print(\"\\n\")\n",
    "            print(stockDetail['Link'],stockDetail['Name'])\n",
    "            print(\"OPEN: \", stockDetail['Open'])\n",
    "            print(\"PREV CLOSE:  \",stockDetail['PrevClose'])\n",
    "            print(\"VOLUME:\",stockDetail['Volume'])\n",
    "            print(\"MARKET CAP:\",stockDetail['MarketCap'])\n",
    "            print(\"\\n\")\n",
    "            loopFlag = False\n",
    "            break\n",
    "        else:\n",
    "            print(\"No such stock found, please try again\")\n",
    "            continue\n",
    "            \n",
    "print(\"Program successfully completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
